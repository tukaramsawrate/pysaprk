from pyspark.sql.functions import *
data="dbfs:/FileStore/tables/tukaramnewtable/bank_full.csv"

df1=spark.read.format("csv").option("inferSchjema","true").option("header","true").option("mode","dropmalformed").option("sep",";").load(data)
#df1.show()
df2=df1.where((col("age")>60) & (col("marital").isin("divorced","married")) &(col("balance")>=1428))
df2.show()




from pyspark.sql import *
from pyspark.sql.functions import *
import re
data="dbfs:/FileStore/tables/tukaramnewtable/10000Records.csv"

df1=spark.read.format("csv").option("inferSchjema","true").option("header","true").option("mode","dropmalformed").load(data)
#df1.show()

col=(re.sub("[^a-zA-Z0-9]","",i)for i in df1.columns)

df1=df1.toDF(*col)

df1.show()



from pyspark.sql import *
from pyspark.sql.functions import *
data1="dbfs:/FileStore/tables/tukaramnewtable/flights.csv"

df2=spark.read.format("csv").option("header","true").option("inferSchema","true").option("mode","dropmalformed").load(data1)
df2=df2.withColumn("dest1",explode(array_distinct(split(col("dest"),"-")))).groupBy("name").count()
df2.show()